# -*- coding: utf-8 -*-
"""Copy of homework01_texts.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17cS6peLMefucj_EwRlviGyg0qDdDQ6ji

## Homework 01. Simple text processing.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import pandas as pd
from IPython import display
from collections import Counter
import re
import operator
import nltk
import heapq
from sklearn.model_selection import train_test_split
from nltk.tokenize import TweetTokenizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, roc_curve
import torch
from torch import nn
from torch.nn import functional as F
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau
from sklearn.metrics import accuracy_score
from collections import defaultdict
from math import log
import gensim.downloader as api

"""### Toxic or not
Your main goal in this assignment is to classify, whether the comments are toxic or not. And practice with both classical approaches and PyTorch in the process.

*Credits: This homework is inspired by YSDA NLP_course.*

*Disclaimer: The used dataset may contain obscene language and is used only as an example of real unfiltered data.*
"""

# In colab uncomment this cell
! wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/homeworks/homework01/utils.py -nc

try:
    data = pd.read_csv('../../datasets/comments_small_dataset/comments.tsv', sep='\t')
except FileNotFoundError:
    ! wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/comments_small_dataset/comments.tsv -nc
    data = pd.read_csv("comments.tsv", sep='\t')

texts = data['comment_text'].values
target = data['should_ban'].values
data[50::200]

#from sklearn.model_selection import train_test_split
texts_train, texts_test, y_train, y_test = train_test_split(texts, target, test_size=0.5, random_state=42)

"""__Note:__ it is generally a good idea to split data into train/test before anything is done to them.

It guards you against possible data leakage in the preprocessing stage. For example, should you decide to select words present in obscene tweets as features, you should only count those words over the training set. Otherwise your algoritm can cheat evaluation.

### Preprocessing and tokenization

Comments contain raw text with punctuation, upper/lowercase letters and even newline symbols.

To simplify all further steps, we'll split text into space-separated tokens using one of nltk tokenizers.

Generally, library `nltk` [link](https://www.nltk.org) is widely used in NLP. It is not necessary in here, but mentioned to intoduce it to you.
"""

#from nltk.tokenize import TweetTokenizer
tokenizer = TweetTokenizer()
preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))

text = 'How to be a grown-up at work: replace "I don\'t want to do that" with "Ok, great!".'
print("before:", text,)
print("after:", preprocess(text),)

# task: preprocess each comment in train and test

texts_train = [preprocess(line) for line in texts_train]#<YOUR CODE>
texts_test = [preprocess(line) for line in texts_test]#<YOUR CODE>

# Small check that everything is done properly
assert texts_train[5] ==  'who cares anymore . they attack with impunity .'
assert texts_test[89] == 'hey todds ! quick q ? why are you so gay'
assert len(texts_test) == len(y_test)

"""### Step 1: bag of words

One traditional approach to such problem is to use bag of words features:
1. build a vocabulary of frequent words (use train data only)
2. for each training sample, count the number of times a word occurs in it (for each word in vocabulary).
3. consider this count a feature for some classifier

__Note:__ in practice, you can compute such features using sklearn. __Please don't do that in the current assignment, though.__
* `from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer`
"""

# task: find up to k most frequent tokens in texts_train,
# sort them by number of occurences (highest first)
# task: find up to k most frequent tokens in texts_train,
# sort them by number of occurences (highest first)
k = min(10000, len(set(' '.join(texts_train).split())))

words, counts = np.unique(' '.join(texts_train).split(), return_counts=True)
words_and_counts = sorted([(w,c) for w,c in zip(words, counts)], key = lambda x: x[1], reverse=True)

bow_vocabulary = [wc[0] for wc in words_and_counts][:k]

print('example features:', words_and_counts[::100])

def text_to_bow(text):
    """ convert text string to an array of token counts. Use bow_vocabulary. """
    result = np.zeros(len(bow_vocabulary))
    words_in_text = text.split()
    for word in words_in_text:
      for i in range(len(bow_vocabulary)):
        if word==bow_vocabulary[i]:
          result[i]+=1

    return np.array(result, 'float32')

X_train_bow = np.stack(list(map(text_to_bow, texts_train)))
X_test_bow = np.stack(list(map(text_to_bow, texts_test)))

# Small check that everything is done properly
k_max = len(set(' '.join(texts_train).split()))
assert X_train_bow.shape == (len(texts_train), min(k, k_max))
assert X_test_bow.shape == (len(texts_test), min(k, k_max))
assert np.all(X_train_bow[5:10].sum(-1) == np.array([len(s.split()) for s in  texts_train[5:10]]))
assert len(bow_vocabulary) <= min(k, k_max)
assert X_train_bow[6, bow_vocabulary.index('.')] == texts_train[6].split().count('.')

"""Now let's do the trick with `sklearn` logistic regression implementation:"""

#from sklearn.linear_model import LogisticRegression
bow_model = LogisticRegression().fit(X_train_bow, y_train)

#from sklearn.metrics import roc_auc_score, roc_curve

for name, X, y, model in [
    ('train', X_train_bow, y_train, bow_model),
    ('test ', X_test_bow, y_test, bow_model)
]:
    proba = model.predict_proba(X)[:, 1]
    auc = roc_auc_score(y, proba)
    plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (name, auc))

plt.plot([0, 1], [0, 1], '--', color='black',)
plt.legend(fontsize='large')
plt.grid()

"""Seems alright. Now let's create the simple logistic regression using PyTorch. Just like in the classwork."""

def create_model(input_size, lr=0.1):
  model = nn.Sequential()
  model.add_module('l1', nn.Linear(input_size,2))

  opt = torch.optim.SGD(model.parameters(), lr=lr)
  return model, opt

"""Remember what we discussed about loss functions! `nn.CrossEntropyLoss` combines both log-softmax and `NLLLoss`.

__Be careful with it! Criterion `nn.CrossEntropyLoss` with still work with log-softmax output, but it won't allow you to converge to the optimum.__ Next comes small demonstration:
"""

X_train_bow_torch = torch.tensor(X_train_bow, dtype=torch.float32)
X_test_bow_torch = torch.tensor(X_test_bow, dtype=torch.float32)

y_train_torch = torch.tensor(y_train, dtype=torch.long)
y_test_torch = torch.tensor(y_test, dtype=torch.long)

bow_nn_model, bow_nn_opt = create_model(k)
bow_nn_scheduler = ReduceLROnPlateau(bow_nn_opt, patience=5)

"""Let's test that everything is fine"""

# example loss
loss_function = nn.CrossEntropyLoss()
loss = loss_function(bow_nn_model(X_train_bow_torch[:3]), y_train_torch[:3])

assert type(loss.item()) == float

"""Here comes small function to train the model. In future we will take in into separate file, but for this homework it's ok to implement it here. """

def train_model(
    model,
    opt,
    lr_scheduler,
    X_train_torch,
    y_train_torch,
    X_val_torch,
    y_val_torch,
    n_iterations=500,
    batch_size=32,
    warm_start=False,
    show_plots=True,
    eval_every=10
):
    if not warm_start:
        for name, module in model.named_children():
            print('resetting ', name)
            try:
                module.reset_parameters()
            except AttributeError as e:
                print('Cannot reset {} module parameters: {}'.format(name, e))

    train_loss_history = []
    train_acc_history = []
    val_loss_history = []
    val_acc_history = []

    local_train_loss_history = []
    local_train_acc_history = []
    for i in range(n_iterations):

        # sample 256 random observations
        ix = np.random.randint(0, len(X_train_torch), batch_size)
        x_batch = X_train_torch[ix]
        y_batch = y_train_torch[ix]

        # predict log-probabilities or logits
        y_predicted = model(x_batch) ### YOUR CODE

        # compute loss, just like before
        ### YOUR CODE
        loss = loss_function(y_predicted, y_batch)

        # compute gradients
        ### YOUR CODE
        loss.backward()

        # Adam step
        ### YOUR CODE
        opt.step()
        # clear gradients
        ### YOUR CODE
        opt.zero_grad()

        local_train_loss_history.append(loss.data.numpy())
        local_train_acc_history.append(
            accuracy_score(
                y_batch.to('cpu').detach().numpy(),
                y_predicted.to('cpu').detach().numpy().argmax(axis=1)
            )
        )

        if i % eval_every == 0:
            train_loss_history.append(np.mean(local_train_loss_history))
            train_acc_history.append(np.mean(local_train_acc_history))
            local_train_loss_history, local_train_acc_history = [], []

            predictions_val = model(X_val_torch)
            val_loss_history.append(loss_function(predictions_val, y_val_torch).to('cpu').detach().item())

            acc_score_val = accuracy_score(y_val_torch.cpu().numpy(), predictions_val.to('cpu').detach().numpy().argmax(axis=1))
            val_acc_history.append(acc_score_val)
            lr_scheduler.step(train_loss_history[-1])

            if show_plots:
                display.clear_output(wait=True)
                plot_train_process(train_loss_history, val_loss_history, train_acc_history, val_acc_history)
    return model

"""Let's run it on the data. Note, that here we use the `test` part of the data for validation. It's not so good idea in general, but in this task our main goal is practice."""

train_model(bow_nn_model, bow_nn_opt, bow_nn_scheduler, X_train_bow_torch, y_train_torch, X_test_bow_torch, y_test_torch)

def plot_roc_nn(model, Xs, ys, names = ['train', 'test']):
  if len(Xs) != len(ys):
    raise BaseException('')
  for i in range(len(Xs)):
    proba = model(Xs[i]).detach().cpu().numpy()[:,1]
    auc = roc_auc_score(ys[i], proba)
    plt.plot(*roc_curve(ys[i], proba)[:2], label='%s AUC=%.4f' % (names[i], auc))

  plt.plot([0, 1], [0, 1], '--', color='black',)
  plt.legend(fontsize='large')
  plt.grid()

plot_roc_nn(bow_nn_model, [X_train_bow_torch, X_test_bow_torch], [y_train, y_test])

"""Try to vary the number of tokens `k` and check how the model performance changes. Show it on a plot."""

def full_cycle(my_k, x_train, x_test):
  my_X_train_torch = torch.tensor(x_train[:,:my_k], dtype=torch.float32)
  my_X_test_torch = torch.tensor(x_test[:,:my_k], dtype=torch.float32)

  my_model, my_opt = create_model(my_k)
  my_lr_scheduler = ReduceLROnPlateau(my_opt, patience=5)

  train_model(my_model, my_opt, my_lr_scheduler, my_X_train_torch, y_train_torch, my_X_test_torch, y_test_torch, show_plots=False)
  my_auc_train = roc_auc_score(y_train, my_model(my_X_train_torch).detach().cpu().numpy()[:,1])
  my_auc_test = roc_auc_score(y_test, my_model(my_X_test_torch).detach().cpu().numpy()[:,1])
  return (my_auc_train,my_auc_test)

my_results = list()
my_ks = [5, 10, 50, 100, 250, 500, 1000, 2500, 5000]
for my_k in my_ks:
    my_results.append(full_cycle(my_k, X_train_bow, X_test_bow))

def plot_dynamics(results, ks):
  plt.figure(figsize=[15,10])
  plt.ylim((0,1))
  plt.plot([mr[0] for mr in results], label='Train roc-auc')
  plt.plot([mr[1] for mr in results], label='Test roc-auc')
  plt.xticks(range(len(ks)), ks)
  plt.legend()

plot_dynamics(my_results, my_ks)

"""### Step 2: implement TF-IDF features

Not all words are equally useful. One can prioritize rare words and downscale words like "and"/"or" by using __tf-idf features__. This abbreviation stands for __text frequency/inverse document frequence__ and means exactly that:

$$ feature_i = { Count(word_i \in x) \times { log {N \over Count(word_i \in D) + \alpha} }}, $$


where x is a single text, D is your dataset (a collection of texts), N is a total number of documents and $\alpha$ is a smoothing hyperparameter (typically 1). 
And $Count(word_i \in D)$ is the number of documents where $word_i$ appears.

It may also be a good idea to normalize each data sample after computing tf-idf features.

__Your task:__ implement tf-idf features, train a model and evaluate ROC curve. Compare it with basic BagOfWords model from above.

__Please don't use sklearn/nltk builtin tf-idf vectorizers in your solution :)__ You can still use 'em for debugging though.

Blog post about implementing the TF-IDF features from scratch: https://triton.ml/blog/tf-idf-from-scratch
"""

# Calculate TF
def twit_tf(twit):
  twit_words = twit.split()
  total_words = len(twit_words)
  twit_words_tf = dict()
  for word in twit_words:
    twit_words_tf[word] = twit_words_tf.get(word, 0) + 1/total_words
  return twit_words_tf

train_tfs = [twit_tf(twit) for twit in texts_train]
test_tfs = [twit_tf(twit) for twit in texts_test]

# Calculate IDF
words_idfs=dict()
for twit in texts_train:
  twit_words = set(twit.split())
  for word in twit_words:
    words_idfs[word] = words_idfs.get(word, 0) + 1

import math
total_docs = len(texts_train)
for k in words_idfs.keys():
  words_idfs[k] = math.log(total_docs/words_idfs[k])

# Calculate TF-IDF
def get_tf_idf(twit_tfs):
  twit_tf_idf = dict()
  for word in twit_tfs.keys():
    twit_tf_idf[word] = twit_tfs[word]*words_idfs.get(word, 0)
  return twit_tf_idf

train_tf_idf_s = [get_tf_idf(twit_tfs) for twit_tfs in train_tfs]
test_tf_idf_s = [get_tf_idf(twit_tfs) for twit_tfs in test_tfs]

# Vectorize
def vectorise(twit_tf_idf):
  result = np.zeros(len(words))
  for word in twit_tf_idf.keys():
    for i in range(len(words)):
      if word==words[i]:
        result[i] = twit_tf_idf[word]
  return result

X_train_tfidf = np.stack(list(map(vectorise, train_tf_idf_s)))
X_test_tfidf = np.stack(list(map(vectorise, test_tf_idf_s)))

"""Same stuff about moel and optimizers here (or just omit it, if you are using the same model as before)."""

X_train_tfidf_torch = torch.tensor(X_train_tfidf, dtype = torch.float32)
X_test_tfidf_torch = torch.tensor(X_test_tfidf, dtype = torch.float32)

tf_idf_k = X_train_tfidf.shape[1]
tf_idf_model, tf_idf_opt = create_model(tf_idf_k)
tf_idf_lr_scheduler = ReduceLROnPlateau(tf_idf_opt, patience=5)
train_model(tf_idf_model, tf_idf_opt, tf_idf_lr_scheduler, X_train_tfidf_torch, y_train_torch, X_test_tfidf_torch, y_test_torch, )

for name, X, y, model in [
    ('train', X_train_tfidf_torch, y_train, tf_idf_model),
    ('test ', X_test_tfidf_torch, y_test, tf_idf_model)
]:
    proba = model(X).detach().cpu().numpy()[:, 1]
    auc = roc_auc_score(y, proba)
    plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (name, auc))

plt.plot([0, 1], [0, 1], '--', color='black',)
plt.legend(fontsize='large')
plt.grid()

my_tf_idf_results = list()
my_tf_idf_ks = [5, 10, 50, 100, 250, 500, 1000, 2500, 5000]
for my_k in my_ks:
    my_tf_idf_results.append(full_cycle(my_k, X_train_tfidf, X_test_tfidf))
plot_dynamics(my_tf_idf_results, my_tf_idf_ks)

def full_cycle_lr(my_lr, x_train, x_test):
  my_X_train_torch = torch.tensor(x_train[:,:1000], dtype=torch.float32)
  my_X_test_torch = torch.tensor(x_test[:,:1000], dtype=torch.float32)

  my_model, my_opt  = create_model(1000)
  my_lr_scheduler = ReduceLROnPlateau(my_opt, patience=5)

  train_model(my_model, my_opt, my_lr_scheduler, my_X_train_torch, y_train_torch, my_X_test_torch, y_test_torch, show_plots=False)
  my_auc_train = roc_auc_score(y_train, my_model(my_X_train_torch).detach().cpu().numpy()[:,1])
  my_auc_test = roc_auc_score(y_test, my_model(my_X_test_torch).detach().cpu().numpy()[:,1])
  return (my_auc_train,my_auc_test)

my_tf_idf_lr_results = list()
my_tf_idf_lrs = np.array([5, 10, 50, 100, 250, 500, 1000, 2500, 5000])/1000
for my_tf_idf_lr in my_tf_idf_lrs:
    my_tf_idf_lr_results.append(full_cycle_lr(my_tf_idf_lr, X_train_tfidf, X_test_tfidf))

plot_dynamics(my_tf_idf_lr_results, my_tf_idf_lrs)

"""Fit your model to the data. No not hesitate to vary number of iterations, learning rate and so on.

_Note: due to very small dataset, increasing the complexity of the network might not be the best idea._
"""

final_model = nn.Sequential()
final_model.add_module('l1' , nn.Linear(5722, 500))
final_model.add_module('l2' , nn.Linear(500, 2))

final_opt = torch.optim.SGD(final_model.parameters(), lr=0.1)
final_lr_scheduler = ReduceLROnPlateau(final_opt, patience=5)

train_model(final_model, final_opt, final_lr_scheduler, X_train_tfidf_torch, y_train_torch, X_test_tfidf_torch, y_test_torch)

for name, X, y, model in [
    ('train', X_train_tfidf_torch, y_train, final_model),
    ('test ', X_test_tfidf_torch, y_test, final_model)
]:
    proba = model(X).detach().cpu().numpy()[:, 1]
    auc = roc_auc_score(y, proba)
    plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (name, auc))

plt.plot([0, 1], [0, 1], '--', color='black',)
plt.legend(fontsize='large')
plt.grid()

"""### Step 3: Comparing it with Naive Bayes

Naive Bayes classifier is a good choice for such small problems. Try to tune it for both BOW and TF-iDF features. Compare the results with Logistic Regression.
"""

def train_nb_clf(X, y):
  classes, freq = defaultdict(lambda:0), defaultdict(lambda:0)

  for i in range(len(y)):
    label = y[i]
    classes[label] += 1  
    feats = X[i, :]
    for feat in feats:
      freq[label, feat] += 1

  for label, feat in freq:               
        freq[label, feat] /= classes[label]
  for c in classes:                       
        classes[c] /= len(y)

  return classes, freq

def classify(classifier, feats):
    classes, prob = classifier
    return min(classes.keys(),         
        key = lambda cl: -log(classes[cl]) + \
            sum(-log(prob.get((cl,feat), 10**(-7))) for feat in feats))

nb_clf_bow = train_nb_clf(X_train_bow, y_train)

nb_bow_test_predictions = list()
for i in range(X_test_bow.shape[0]):
  nb_bow_test_predictions.append(classify(nb_clf_bow, X_test_bow[i,:]))

roc_auc_score(y_test, nb_bow_test_predictions)*2-1

nb_clf_tfidf = train_nb_clf(X_train_tfidf, y_train)

nb_tfidf_test_predictions = list()
for i in range(X_test_tfidf.shape[0]):
  nb_tfidf_test_predictions.append(classify(nb_clf_tfidf, X_test_tfidf[i,:]))

roc_auc_score(y_test, nb_tfidf_test_predictions)*2-1

fpr, tpr, _ = roc_curve(y_test, nb_tfidf_test_predictions)
auc = roc_auc_score(y_test, nb_tfidf_test_predictions)*2-1
plt.plot(fpr, tpr, label = 'test TD-IDF. AUC %.4f' % auc)

fpr, tpr, _ = roc_curve(y_test, nb_bow_test_predictions)
auc = roc_auc_score(y_test, nb_tfidf_test_predictions)*2-1
plt.plot(fpr, tpr, label = 'test BoW. AUC %.4f' % auc)

plt.plot([0, 1], [0, 1], '--', color='black',)
plt.legend(fontsize='large')
plt.grid()

"""Shape some thoughts on the results you aquired. Which model has show the best performance? Did changing the learning rate/lr scheduler help?

The best result was shown by the neural network at TF-IDF. It overfitted less (less roc-auc on the train than on other models) and works better on the test set.

An increase in the number of features leads to an increase in the quality of the model, but also increases the tendency to overfit.

An Increase of LR also increased overfitting

### Step 4: Using the external knowledge.

Use the `gensim` word2vec pretrained model to translate words into vectors. Use several models with this new encoding technique. Compare the results, share your thoughts.
"""

texts_train_arr = [tt.split() for tt in texts_train]
texts_test_arr = [tt.split() for tt in texts_test]

pretrained_w2v = api.load('glove-twitter-25')

def twit_to_vec(twit):
  twit_vec = []
  for word in twit:
    try:
      word_vec = pretrained_w2v.wv.get_vector(word)
      twit_vec.append(word_vec)
    except:
      pass
  if len(twit_vec) == 0:
    return np.zeros(25)
  else:
    return np.mean(twit_vec, axis=0)

X_train_w2v = np.stack(list(map(twit_to_vec, texts_train_arr)))
X_test_w2v = np.stack(list(map(twit_to_vec, texts_test_arr)))

X_train_w2v_torch = torch.tensor(X_train_w2v, dtype=torch.float32)
X_test_w2v_torch = torch.tensor(X_test_w2v, dtype=torch.float32)

w2v_model, w2v_opt = create_model(25)
w2v_lr_scheduler = ReduceLROnPlateau(w2v_opt, patience=5)

train_model(w2v_model, w2v_opt, w2v_lr_scheduler, X_train_w2v_torch, y_train_torch, X_test_w2v_torch, y_test_torch, )

for name, X, y, model in [
    ('train', X_train_w2v_torch, y_train, w2v_model),
    ('test ', X_test_w2v_torch, y_test, w2v_model)
]:
    proba = model(X).detach().cpu().numpy()[:,1]
    auc = roc_auc_score(y, proba)
    plt.plot(*roc_curve(y, proba)[:2], label='%s AUC=%.4f' % (name, auc))

plt.plot([0, 1], [0, 1], '--', color='black',)
plt.legend(fontsize='large')
plt.grid()

"""The pre-trained embeddings have shown themselves to be excellent. The model obtained on them, having the same architecture as before, showed a low tendency to overfitting and high quality on deferred sampling."""