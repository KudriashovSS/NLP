{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "homework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eulvfJWl7ueY"
      },
      "source": [
        "## Homework 02: Unsupervised embedding-based MT\n",
        "*Note: this homework is based on open materials from yandexdataschool [NLP course](https://github.com/yandexdataschool/nlp_course/). Feel free to check this awesome course if you wish to dig deeper.*\n",
        "\n",
        "*Refined by [Nikolay Karpachev](https://www.linkedin.com/in/nikolay-karpachev-b0146a104/)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV4rIjxa7uei"
      },
      "source": [
        "**In this homework** **<font color='red'>YOU</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully), in particular for similar languages, e.g. Ukrainian and Russian. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idSYq2GU7uew"
      },
      "source": [
        "### Frament of the Swadesh list for some slavic languages\n",
        "\n",
        "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
        "\n",
        "So we can see some kind of word invariance for different Slavic languages.\n",
        "\n",
        "\n",
        "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
        "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
        "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
        "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
        "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
        "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
        "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
        "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
        "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
        "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
        "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
        "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
        "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
        "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
        "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
        "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
        "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
        "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
        "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
        "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
        "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
        "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
        "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNM3_fjr7ue2"
      },
      "source": [
        "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLppwa527ue6"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYBGKAUn7ue_"
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwGoVhRA7ufP"
      },
      "source": [
        "In this notebook we're going to use pretrained word vectors - FastText (original paper - https://arxiv.org/abs/1607.04606).\n",
        "\n",
        "You can download them from the official [website](https://fasttext.cc/docs/en/crawl-vectors.html). We're going to need embeddings for Russian and Ukrainian languages. Please use word2vec-compatible format (.text)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS_DD7BYYHtF",
        "outputId": "a31af749-63b9-4123-a4ae-5440e426f702",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.bin.gz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 23:17:13--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4504123670 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.uk.300.bin.gz’\n",
            "\n",
            "cc.uk.300.bin.gz    100%[===================>]   4.19G  22.6MB/s    in 3m 11s  \n",
            "\n",
            "2021-04-18 23:20:24 (22.5 MB/s) - ‘cc.uk.300.bin.gz’ saved [4504123670/4504123670]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e7iVtz2blex",
        "outputId": "2d9f6997-e940-41fd-bfbf-2167dbabb786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gzip -d cc.uk.300.bin.gz"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: cc.uk.300.bin already exists; do you wish to overwrite (y or n)? y\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1JjQv_97ufT"
      },
      "source": [
        "uk_emb = gensim.models.FastText.load_fasttext_format(\"cc.uk.300.bin\")\n",
        "uk_emb = uk_emb.wv"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rlkGjFabuT4",
        "outputId": "5e3c7d32-a807-429b-8f82-42da2057bed3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 23:23:58--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4496459151 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.ru.300.bin.gz’\n",
            "\n",
            "cc.ru.300.bin.gz    100%[===================>]   4.19G  23.7MB/s    in 3m 1s   \n",
            "\n",
            "2021-04-18 23:26:59 (23.7 MB/s) - ‘cc.ru.300.bin.gz’ saved [4496459151/4496459151]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEEJD2rRbwCv",
        "outputId": "0b70e2a8-22c7-4a4c-f31d-82991386a0d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gzip -d cc.ru.300.bin.gz"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: cc.ru.300.bin already exists; do you wish to overwrite (y or n)? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffzuept_7ufd"
      },
      "source": [
        "ru_emb = gensim.models.FastText.load_fasttext_format(\"cc.ru.300.bin\")\n",
        "ru_emb = ru_emb.wv"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTkXfT0W7ufk",
        "outputId": "bbb422c6-5897-4ed2-96f1-0e2a238f300f"
      },
      "source": [
        "ru_emb.most_similar([ru_emb[\"август\"]], topn=10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('август', 1.0),\n",
              " ('июль', 0.8918135166168213),\n",
              " ('июнь', 0.8817341327667236),\n",
              " ('март', 0.8627270460128784),\n",
              " ('ноябрь', 0.850366473197937),\n",
              " ('октябрь', 0.8314876556396484),\n",
              " ('декабрь', 0.8227221965789795),\n",
              " ('январь', 0.8169068098068237),\n",
              " ('апрель', 0.7869453430175781),\n",
              " ('сентябрь', 0.7696788311004639)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdBA8lcg7ufs",
        "outputId": "441138ec-12a0-4516-c424-0dba0a9eb58b"
      },
      "source": [
        "uk_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('серпень', 1.0),\n",
              " ('серпеня', 0.882050633430481),\n",
              " ('серпені', 0.8710206151008606),\n",
              " ('серпен', 0.8673141002655029),\n",
              " ('серпень-жовтень', 0.852085530757904),\n",
              " ('серпнясерпень', 0.8448044657707214),\n",
              " ('лютий-серпень', 0.8408336639404297),\n",
              " ('серпентарій', 0.8381907939910889),\n",
              " ('серпень.Температури', 0.8358946442604065),\n",
              " ('травень-серпень', 0.8319928050041199)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNdYAR1q7uf6"
      },
      "source": [
        "Load small dictionaries for correspoinding words pairs as trainset and testset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35d_DAK67uf8"
      },
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\") as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkNL602WHJyO",
        "outputId": "ee9f4af2-d1ca-4db9-c41c-a19d5e953feb"
      },
      "source": [
        "!wget -O ukr_rus.train.txt http://tiny.cc/jfgecz"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 23:35:10--  http://tiny.cc/jfgecz\n",
            "Resolving tiny.cc (tiny.cc)... 157.245.113.153\n",
            "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://tiny.cc/jfgecz [following]\n",
            "--2021-04-18 23:35:10--  https://tiny.cc/jfgecz\n",
            "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt [following]\n",
            "--2021-04-18 23:35:10--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59351 (58K) [text/plain]\n",
            "Saving to: ‘ukr_rus.train.txt’\n",
            "\n",
            "ukr_rus.train.txt   100%[===================>]  57.96K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-04-18 23:35:10 (4.65 MB/s) - ‘ukr_rus.train.txt’ saved [59351/59351]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoclU6JcHCcn",
        "outputId": "04994587-3b9d-443b-82f1-ee73fc316e04"
      },
      "source": [
        "!wget -O ukr_rus.test.txt http://tiny.cc/6zoeez"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 23:35:11--  http://tiny.cc/6zoeez\n",
            "Resolving tiny.cc (tiny.cc)... 157.245.113.153\n",
            "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://tiny.cc/6zoeez [following]\n",
            "--2021-04-18 23:35:11--  https://tiny.cc/6zoeez\n",
            "Connecting to tiny.cc (tiny.cc)|157.245.113.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt [following]\n",
            "--2021-04-18 23:35:11--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week01_embeddings/ukr_rus.test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12188 (12K) [text/plain]\n",
            "Saving to: ‘ukr_rus.test.txt’\n",
            "\n",
            "ukr_rus.test.txt    100%[===================>]  11.90K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-18 23:35:11 (76.1 MB/s) - ‘ukr_rus.test.txt’ saved [12188/12188]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05BqsdSK7ugD"
      },
      "source": [
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQOZw51r7ugL"
      },
      "source": [
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZBBNvpz7ugQ"
      },
      "source": [
        "## Embedding space mapping (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Dhk5gL7ugS"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
        "or\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
        "\n",
        "where $||*||_F$ - Frobenius norm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acOjDdtL7ugY"
      },
      "source": [
        "$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb-KN1be7uga"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# YOUR CODE HERE\n",
        "mapping = LinearRegression(fit_intercept=True).fit(X_train, Y_train)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7tqJwoY7ugf"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31SrFSbn7ugi",
        "outputId": "16d961d2-070a-4761-b8a4-d3ab31088719"
      },
      "source": [
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august, topn=10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('март', 0.5900105237960815),\n",
              " ('ноябрь', 0.5561882257461548),\n",
              " ('январь', 0.5516124963760376),\n",
              " ('февраль', 0.5507173538208008),\n",
              " ('апрель', 0.507216215133667),\n",
              " ('июнь', 0.5049359798431396),\n",
              " ('август', 0.5006322264671326),\n",
              " ('декабрь', 0.49596941471099854),\n",
              " ('зима', 0.48768675327301025),\n",
              " ('солнцестояние', 0.48156559467315674)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okSkjk597ugo"
      },
      "source": [
        "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2uY6Y9B7ugt"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zptuho8LAfIE"
      },
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...] \n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    num_matches = 0\n",
        "    k = 0\n",
        "    for i, (_, ru) in enumerate(pairs):\n",
        "        # YOUR CODE HERE\n",
        "        word, value = zip(*ru_emb.most_similar(mapped_vectors[k].reshape(1, -1), topn = topn))\n",
        "        num_matches += int(ru in word)\n",
        "        k = k + 1\n",
        "    precision_val = round(num_matches / len(pairs), 2) \n",
        "    return precision_val"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duhj9hpv7ugy"
      },
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-iyd5gP7ug5"
      },
      "source": [
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ssEJ3x7uhA"
      },
      "source": [
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUd41GeT05ow",
        "outputId": "e2931bd2-a6df-4769-875b-a67960d7b415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(precision_top1, precision_top5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47 0.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf6Ou8bx7uhH"
      },
      "source": [
        "## Making it better (orthogonal Procrustean problem) (0.3 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oLs-drN7uhK"
      },
      "source": [
        "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal. \n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$W^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KSaRJFGMFiJ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdFQ7qti7uhL"
      },
      "source": [
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\" \n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    a = X_train.T @ Y_train\n",
        "    u, s, vh = np.linalg.svd(a)\n",
        "    # compute orthogonal embedding space mapping\n",
        "    mapping = u @ vh\n",
        "\n",
        "    return mapping"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X7QfYDd7uhQ"
      },
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVOFYYa37uhX",
        "outputId": "88557d94-bc0d-494d-cb54-32f4f493129e"
      },
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('март', 0.4410023093223572),\n",
              " ('февраль', 0.430755078792572),\n",
              " ('ноябрь', 0.4286820888519287),\n",
              " ('декабрь', 0.407553493976593),\n",
              " ('январь', 0.4010366201400757),\n",
              " ('июль', 0.3999900817871094),\n",
              " ('октябрь', 0.3791142702102661),\n",
              " ('июнь', 0.37881380319595337),\n",
              " ('август', 0.3679208755493164),\n",
              " ('апрель', 0.35369962453842163)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r297sYP37uhb",
        "outputId": "8e841e16-7571-4b00-f128-9d4eb2cde1a8"
      },
      "source": [
        "print(precision(uk_ru_test, np.matmul(X_test, W)))\n",
        "print(precision(uk_ru_test, np.matmul(X_test, W), 5))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.52\n",
            "0.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvUZ72U5AfJg"
      },
      "source": [
        "## Unsupervised embedding-based MT (0.4 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyuVfHBLrJn"
      },
      "source": [
        "Now, let's build our word embeddings-based translator!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPAURW1CMuP7"
      },
      "source": [
        "Firstly, download OPUS Tatoeba corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F80kUKzQMsDu",
        "outputId": "5acd365d-3a54-4ec0-9981-5765920dd1c2"
      },
      "source": [
        "!wget https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-18 23:43:25--  https://object.pouta.csc.fi/OPUS-Tatoeba/v20190709/mono/uk.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1819128 (1.7M) [application/gzip]\n",
            "Saving to: ‘uk.txt.gz’\n",
            "\n",
            "uk.txt.gz           100%[===================>]   1.73M  2.33MB/s    in 0.7s    \n",
            "\n",
            "2021-04-18 23:43:27 (2.33 MB/s) - ‘uk.txt.gz’ saved [1819128/1819128]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CGFZoxCUVf1",
        "outputId": "499ae8a4-8e6d-496c-f0cd-1b0334d06ee1"
      },
      "source": [
        "!gzip -d ./uk.txt.gz"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: ./uk.txt already exists; do you wish to overwrite (y or n)? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MV3VvoVUX5U"
      },
      "source": [
        "with open('./uk.txt', 'r') as f:\n",
        "    uk_corpus = f.readlines()"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU7nPVf0UhbI"
      },
      "source": [
        "# To save your time and CPU, feel free to use first 1000 sentences of the corpus\n",
        "uk_corpus = uk_corpus[:1000]"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GujNwTF1fMum",
        "outputId": "9fd437d0-0b0f-4e44-ee77-afc8a46d7f17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(sentence_data)\n",
        "uk_corpus = [word_tokenize(token) for token in uk_corpus]\n",
        "k = 0\n",
        "for word in uk_corpus:\n",
        "  uk_corpus[k] = \" \".join(uk_corpus[k])\n",
        "  k +=1"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGksC7l_NMi9"
      },
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    \n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    translated = str(sentence)\n",
        "    sentence = sentence.split(' ')\n",
        "    # YOUR CODE GOES HERE\n",
        "    for word in sentence:\n",
        "        # find ukrainian embedding for each word in sentence\n",
        "        ebmdn = uk_emb[word]\n",
        "        # transform ukrainian embedding vector \n",
        "        # find nearest russian word and replace\n",
        "        russian, _ = zip(*ru_emb.most_similar([np.matmul(ebmdn, W)], topn=1))\n",
        "        translated = translated.replace(word, russian[0])\n",
        "    translated = translated.split(' ')\n",
        "    return \" \".join(translated)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hbbMy-tNxlf"
      },
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышь\""
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia6I2ce7O_HI"
      },
      "source": [
        "Now you can play with your model and try to get as accurate translations as possible. **Note**: one big issue is out-of-vocabulary words. Try to think of various ways of handling it (you can start with translating each of them to a special **UNK** token and then move to more sophisticated approaches). Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "386T61BICIuG"
      },
      "source": [
        "UNK = 'Missed'"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap1W7ZCeOAVU",
        "outputId": "d6c41752-681d-413e-f55d-97ae4c0a4f55"
      },
      "source": [
        "for sent in uk_corpus[::10]:\n",
        "      print(sent, ' ', translate(sent))"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Я вже закінчу коледж , коли ви вернетеся з Америки .   мной уже прилечу колледж , когда мы житьИ со Америку .\n",
            "Місто бомбардували ворожі літаки .   город бомбардировали вражеские самолёты .\n",
            "Можливо , я антисоціальний , але це не означає , що я не спілкуюся з людьми .   Врмнойд , мной дерсокий , но это не осоначает , что мной не спілкуюсмной со людьми .\n",
            "Цього ранку випала роса .   Тогда утро выпала роса .\n",
            "Біда не приходить одна .   Беда не приходит одна .\n",
            "Подивися на той дим .   Разуй по тот дым .\n",
            "Я замовив два гамбургера .   мной заказал два бургера .\n",
            "Я не хотів нікого образити .   мной не хотел НИКОГО оскорбить .\n",
            "Гора вкрита снігом .   гора покрыта снегом .\n",
            "На фотографії в дівчини корона не з золота , а з квітів .   по снимки во дівочини корона не со соолота , а со квоітіво .\n",
            "У мене є мрія .   Во меня является мечта .\n",
            "Я приїхав у Японію з Китаю .   мной приехал во мнойпонію со китая. .\n",
            "На півночі знаходиться Шотландія ; на півдні — Англія ; на заході — Уельс ; і ще далі на заході — Північна Ірландія .   по юг походится Шотландия ; по юге — Англия ; по югу — Осрик ; и еще дали по югу — Пивничпо Ірландия .\n",
            "Його рідна країна — Німеччина .   .Его родная страна — Япония .\n",
            "Берн — столиця Швейцарії .   Окленд — столица Финляндии .\n",
            "Він чекав на нього до десятої години .   он ждал по него к десятой часа .\n",
            "Ти можеш взяти цю книгу даром .   Tы смеешь взять ту книгу даром .\n",
            "Цей роман написав відомий американський письменник .   Этот роман написал известный американский литератор .\n",
            "Забронюйте , будьте ласкаві , кімнату біля міжнародного аеропорту в Торонто .   арендуйте , будьте ласковоые , комнату воозле многонациональное аэропорту во Монреаль .\n",
            "Він знає , що ти його кохаєш ?   он знает , что ты ее безответна ?\n",
            "Я знаю , що ти багатий .   мной Знаю , что ты багатый .\n",
            "Ті , хто все забувають , щасливі .   Те , кто всё забывают , счастливые .\n",
            "В цій річці небезпечно плавати .   Во внашей реке опасно плавать .\n",
            "Прийшов , побачив , переміг .   пришедший , увидел , победил .\n",
            "Я ходжу до школи пішки .   мной Хожу к школы пёхом .\n",
            "Не твоя справа !   Не твоя дело !\n",
            "Не забудь квиток .   Не обещай билет .\n",
            "Хто він ?   Кто он ?\n",
            "Ви будете чай чи каву ?   мы будуте чай ли кофе ?\n",
            "Він не піде на пікнік , як і я .   он не идти по турпоход , как и мной .\n",
            "Коли Ви народилися ?   Когда мы родились ?\n",
            "Це моя улюблена пісня .   это моя любимая песня .\n",
            "Ми майже сім ’ я .   мы почти семь мной мной .\n",
            "Який гарний сьогодні місяць !   Какой хороший сегодня год !\n",
            "Я проти будь-яких війн .   мной против отсутствии войны .\n",
            "Поверхня повітряної кулі — неевклідовий простір , тому для неї не виконуються правила евклідової геометрії .   Кромка воздушной шар — Анатолийское пространство , поэтому для неё не выполняются правила полиномиальной геометрии .\n",
            "Кажуть , що американці вважають кількість грошей , яку заробляє людина , мірилом його уміння .   ведь , что американцы считают кол-во денег , которую тратит человек , мерилом ее умение .\n",
            "Можна я примірю це плаття ?   Можно мной предложение0.0Оставить это платтмной ?\n",
            "Якщо буде гарна погода , ми доберемося туди завтра .   если будет замечательная погода , мы въедем туда завтра .\n",
            "Це був злий заєць .   это был злой заяц .\n",
            "Один , два , три , чотири , п'ять , шість , сім , вісім , дев'ять , десять .   один , два , три , четыре , седьмым , шесть , семь , вісемь , валокардин , десять .\n",
            "Хто в любові не знається , той горя не знає .   Кто во любовоі не поднаторел , тот горя не знает .\n",
            "Його мати хвилюється за нього .   .Его иметь нервничает за него .\n",
            "Я поважаю тих , хто старається з усіх сил .   мной уважаю кто , кто старается со всех сил .\n",
            "Їхня дружба переросла у глибоке кохання .   чья дрвожба переросшая во глубокое счастье .\n",
            "Кейт п ’ є багато молока кожен день .   Кейт пя мной является много молока каждый день .\n",
            "Він злодій .   он вор .\n",
            "Шумового забруднення можна було б позбігнути тільки якщо б люди були більш чутливими до навколишнього середовища .   ОсетияРепортажиАналитика загрязнение можно быыыло быы позбыыігнути только если быы люди быыули быыільш зависим к окружающей сереквища .\n",
            "Чай з лимоном , будьте ласкаві .   Чай со лимоном , будьте ласковые .\n",
            "Не плутай бажання з коханням .   Не подпирать желание со сеновале .\n",
            "Я би з задоволенням написав сотні речень в Tatoeb ’ і , але в мене є справи .   мной бы со соадовоооленням написал сотни рифмовооку воо Корпоративока мной и , но воо меня является справоои .\n",
            "Дайте мені філіжанку кави .   Дать мне чашечку кофе .\n",
            "Але ж ти ніколи мені про це не розповідала !   Но же ты никогда мне о это не поведала !\n",
            "У тебе будуть проблеми , якщо твої батьки довідаються .   Во тебя будут проблемы , если твои родители увидят .\n",
            "Запах троянд наповнив кімнату .   Запах розы наполнил комнату .\n",
            "Як у тебе справи ?   .Как во тебя дело ?\n",
            "Це мої штани .   это мои штаны .\n",
            "Ні , дякую .   Да , спасибо .\n",
            "Я не розумію , чому Німеччина перемогла на Євробаченні .   мной не понимаю , почему Япония победила по maNga .\n",
            "Добрий вечір .   -Добрый вечер .\n",
            "З юбілеєм Олексія Дударева привітав Президент Білорусі Олександр Лукашенко .   .С микроволновые Cчет б2 поздравил президент Эстонии г-н Ельцин .\n",
            "Чумацький шлях — широкий пояс із далеких зірок , кожна зірка — сонце , таке як наше .   Чумацкий путь — широкий пояс со далёких звезд , каждая звезда — солнце , такое как наше .\n",
            "Незвичайно бачити рок-зірок з краваткою !   Необыкновенно видеть панк-рокеры со манишкой !\n",
            "Усе печиво у формі зірок .   это печенье во форме звезд .\n",
            "Що мені вдягнути — штани чи спідницю ?   ЧТо мне одеть — штаны ли юбку ?\n",
            "Гартман Вітвер — відомий львівський скульптор .   усмехается Натаниел — известный питерский скульптор .\n",
            "То був злий кролик .   Ну был злой кролик .\n",
            "Можеш взяти будь-який , що тобі до сподоби .   -могу взять любой , что тебе к спокби .\n",
            "Звичайно я піду .   ведь мной пойдете .\n",
            "Шовкопряди прядуть кокони .   бражника заплетают коконы .\n",
            "Що б ти зробила , якщо б у тебе було , скажім , десять тисяч доларів ?   ЧТо быы ты зробыыила , если быы во тебыые быыволо , стихиру , десять тысяч долл. ?\n",
            "Він думає , що він хтось , а насправді він ніхто .   он думает , что он кто-нибудь , а это он никто .\n",
            "Вона дуже пишається своєю колекцією марок .   она очень гордится своею коллекцией марок .\n",
            "Він дуже простий ...   он очень простой ..\n",
            "Яка ти добра !   какая ты добра !\n",
            "Як я за тобою скучив !   .Как мной за тобой сдружился !\n",
            "Це все , що я знаю .   это всё , что мной Знаю .\n",
            "Ти ведеш щоденник ?   Tы пялишься дневник ?\n",
            "Тобі вирішувати .   тебе решать .\n",
            "Це пошта , а то — банк .   это почта , а то — банк .\n",
            "Це все , що я хочу зробити .   это всё , что мной хочу сделать .\n",
            "Я вперше дивлюся такий страшний фільм .   мной впервые смотрю такой жуткий кинофильм .\n",
            "Ця пісня нагадує мені про дім .   та песня напоминает мне о дом .\n",
            "Хіросі тут ?   экранизированы тут ?\n",
            "Мене звуть Джек .   Меня зовут Джек .\n",
            "Як людина живе , так вона і помре .   .Как человек живёт , да она и умрет .\n",
            "Я тут уже дві години .   мной тут уже две часа .\n",
            "Мені треба вибачитись перед Ен .   .Мне надо извиниться перед .Т .\n",
            "Сьогодні я бачив шпака .   Нынче мной видел варакушка .\n",
            "« Скільки коштує ця носова хусточка ? » — « Дев'яносто п'ять центів » .   « Сколько стоить та носовая серёжка ? » — « чёрно-белый седьмым центов » .\n",
            "Ранені ведмеді , як правило , дуже небезпечні .   Кусикова медведи , как обычно , очень опасные .\n",
            "Він швидко втомлюється .   он быстро устает .\n",
            "Усі готові .   Оба готовы .\n",
            "Він скучає по своїй сім'ї .   он блажит по своей Люневиле .\n",
            "« Дякую » , — « На здоров'я » .   « спасибо » , — « по переживайте » .\n",
            "Я ще не знаю своєї адреси , я певний час буду жити в подруги .   мной еще не Знаю свооей адреса , мной некий момент буду жить во подруги .\n",
            "Амазонка— друга по довжині ріка в світі після Ніла .   ВладивоостокВ первоая по длине река во своіті после Дина .\n",
            "А якщо побачиш Тома , передай йому від мене вітання .   из если увидишь Итана , Валентинку ему от меня приветствие .\n",
            "Закрий за собою двері .   закрой за собой дверь .\n",
            "Тримай при собі словник .   Жжёт при себя меседж .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyLZ1xQC-M5M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}